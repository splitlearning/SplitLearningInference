{"version":3,"sources":["App.tsx","reportWebVitals.ts","index.tsx"],"names":["RESNET18_CLIENT_MODEL_URL","RESNET18_SERVER_MODEL_URL","App","props","session","InferenceSession","backendHint","preprocessImage","img","orgWidth","width","orgHeight","height","resizedHeight","resizedWidth","console","log","canvas","document","createElement","getContext","drawImage","data","getImageData","dataFromImage","ndarray","Float32Array","dataProcessed","ops","assign","pick","divseq","subseq","Tensor","classifyImage","a","inputImg","getElementById","state","modelLoaded","setState","loading","loadModel","splitLayer","imgTensor","run","clientOutputMap","splitActivation","values","next","value","dims","npActivation","requestOptions","method","headers","body","JSON","stringify","Array","from","fetch","then","response","json","class","error","updatePreview","style","display","file","files","imageURL","URL","createObjectURL","updateRangePreview","parseInt","className","id","src","this","type","min","max","step","onChange","accept","onClick","Component","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode"],"mappings":"oUAoBMA,EAA4B,sEAE5BC,EAA4B,kDAyLnBC,E,kDAnLb,WAAYC,GAAe,IAAD,8BACxB,cAAMA,IAHRC,QAAU,IAAIC,mBAAiB,CAAEC,YAAa,QAEpB,EAgB1BC,gBAAkB,SAACC,GAEjB,IAAIC,EAAWD,EAAIE,MACfC,EAAYH,EAAII,OAChBC,EAAgB,IAChBC,EAAe,IACfL,EAAWE,EACbG,EAAgBL,EAAWE,EAAa,IAC/BF,EAAWE,IACpBE,EAAiBF,EAAYF,EAAY,KAE3CM,QAAQC,IAAI,YAAcP,EAAW,OAASE,EAAY,iBAAmBG,EAAe,OAASD,EAAgB,OAGrH,IAAII,EAASC,SAASC,cAAc,UAMpC,GALAF,EAAOP,MAAQI,EACfG,EAAOL,OAASC,EAChBI,EAAOG,WAAW,MAAMC,UAAUb,EAAK,EAAG,EAAGM,EAAcD,GAGvDA,EAAgBC,EAElB,IAAIQ,EAAOL,EAAOG,WAAW,MAAMG,aAAa,GAAIV,EAAgB,KAAK,EAAG,IAAK,KAAOA,EAAgB,KAAK,GAAGS,UAG5GA,EAAOL,EAAOG,WAAW,MAAMG,aAAa,EAAG,EAAG,IAAK,KAAKD,KAIlE,IAAME,EAAgBC,IAAQ,IAAIC,aAAaJ,GAAO,CAAC,IAAK,IAAK,IAC3DK,EAAgBF,IAAQ,IAAIC,aAAa,QAAgB,CAAC,EAAG,EAAG,IAAK,MAmB3E,OAlBAE,IAAIC,OAAOF,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAON,EAAcM,KAAK,KAAM,KAAM,IAChFF,IAAIC,OAAOF,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAON,EAAcM,KAAK,KAAM,KAAM,IAChFF,IAAIC,OAAOF,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAON,EAAcM,KAAK,KAAM,KAAM,IAGhFF,IAAIG,OAAOJ,EAAe,KAG1BC,IAAII,OAAOL,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MACjDF,IAAII,OAAOL,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MACjDF,IAAII,OAAOL,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MACjDF,IAAIG,OAAOJ,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MACjDF,IAAIG,OAAOJ,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MACjDF,IAAIG,OAAOJ,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MAGjC,IAAIG,SAAQN,EAAcL,KAAuB,UAAW,CAAC,EAAG,EAAG,IAAK,OA/DhE,EAoE1BY,cApE0B,sBAoEV,sCAAAC,EAAA,yDACVC,EAAWlB,SAASmB,eAAe,aAGlC,EAAKC,MAAMC,YAJF,uBAKZ,EAAKC,SAAS,CACZC,QAAS,4BANC,SAQN,EAAKrC,QAAQsC,UAAU1C,EAA4B,sBAAwB,EAAKsC,MAAMK,WAAa,SAR7F,OASZ5B,QAAQC,IAAI,4BAA8BhB,EAA4B,sBAAwB,EAAKsC,MAAMK,WAAa,SACtH,EAAKH,SAAS,CACZD,aAAa,IAXH,WAeVH,EAfU,wBAiBZ,EAAKI,SAAS,CACZC,QAAS,8BAEPG,EAAY,EAAKrC,gBAAgB6B,GACrCrB,QAAQC,IAAI,uBAAyB4B,EAAUtB,MArBnC,UAsBkB,EAAKlB,QAAQyC,IAAI,CAACD,IAtBpC,QAsBNE,EAtBM,OAuBNC,EAAkBD,EAAgBE,SAASC,OAAOC,MACxDnC,QAAQC,IAAI,6CAA+C+B,EAAgBzB,MAC3EP,QAAQC,IAAI,eAAiB+B,EAAgBI,MAC7CpC,QAAQC,IAAI+B,EAAgBzB,KAAK,IAC7B8B,EAAe3B,IAAQsB,EAAgBzB,KAAMyB,EAAgBI,MACjEpC,QAAQC,IAAIoC,GACZrC,QAAQC,IAAIoC,EAAatB,KAAK,EAAG,EAAG,KAAM,OAG1C,EAAKU,SAAS,CACZC,QAAS,qEAAuE,EAAKH,MAAMK,WAAY,UAEnGU,EAAiB,CACnBC,OAAQ,OACRC,QAAS,CAAE,eAAgB,oBAC3BC,KAAMC,KAAKC,UAAU,CAACP,KAAMJ,EAAgBI,KAAM7B,KAAMqC,MAAMC,KAAKb,EAAgBzB,MAAOqB,WAAY,EAAKL,MAAMK,cAErH5B,QAAQC,IAAI,cAAgBf,EAA4B,wBAA0B,EAAKqC,MAAMK,YAC7FkB,MAAM5D,EAA2BoD,GAC5BS,MAAK,SAAAC,GAAQ,OAAIA,EAASC,UAC1BF,MAAK,SAAAxC,GAEJ,EAAKkB,SAAS,CAACyB,MAAO3C,EAAK2C,MAAOxB,QAAS,UA7CrC,wBAgDZ1B,QAAQmD,MAAM,sEAhDF,4CApEU,EA2H1BC,cAAgB,WACdjD,SAASmB,eAAe,eAAe+B,MAAMC,QAAU,QACvD,IAAMC,EAAQpD,SAASmB,eAAe,cAAmCkC,MAAM,GAC/ExD,QAAQC,IAAIsD,GACRA,GACA,EAAK9B,SAAS,CAAEgC,SAAUC,IAAIC,gBAAgBJ,KAElDpD,SAASmB,eAAe,eAAe+B,MAAMC,QAAU,QAlI/B,EAqI1BM,mBAAqB,WACnB,IAAMhC,EAAczB,SAASmB,eAAe,mBAAwCa,MACpF,EAAKV,SAAS,CAAEG,WAAYiC,SAASjC,MArIrC,EAAKL,MAAQ,CACTG,QAAS,KACTF,aAAa,EACb0B,MAAO,KACPO,SAAU,KACV7B,WAAY,GAPQ,E,0CA0I1B,WACE,OACE,qBAAKkC,UAAU,MAAf,SACE,yBAAQA,UAAU,aAAlB,UACE,+DACA,oBAAGA,UAAU,OAAb,wDAC6C,oCAD7C,2BAC0E,uCAD1E,gBACoG,uCADpG,aAGA,qBAAKC,GAAG,wBAAwBC,IAAI,gCACpC,oBAAGF,UAAU,OAAb,kBACO,+CADP,uDACgF,kDADhF,yCAEE,uBACA,uBAHF,iGAIgG,8CAJhG,oCAKE,uBACA,uBANF,8BAO6B,0CAP7B,4BAOsE,4CAPtE,iBAOsG,gEAPtG,OAS0B,OAAvBG,KAAK1C,MAAMG,QACZ,gCACE,iDAA0B,uBAAOqC,GAAG,kBAAkBG,KAAK,QAAQC,IAAI,IAAIhC,MAAO8B,KAAK1C,MAAMK,WAAYwC,IAAI,IAAIC,KAAK,IAAIC,SAAUL,KAAKL,qBAD3I,OACuK,sBAAMG,GAAG,oBAAT,SAA8BE,KAAK1C,MAAMK,aAC9M,uBACA,uBACA,uBAAO0C,SAAUL,KAAKb,cAAec,KAAK,OAAOH,GAAG,aAAaQ,OAAO,eACxE,uBACA,uBACA,qBAAKR,GAAG,cAAcD,UAAU,WAC9BG,KAAK1C,MAAM2B,MAAQ,wCAAWe,KAAK1C,MAAM2B,SAAa,iCAAM,uBAAM,0BACpE,qBAAKa,GAAG,YAAYC,IAAKC,KAAK1C,MAAMkC,SAAUJ,MAAO,CAACC,QAAkC,OAAxBW,KAAK1C,MAAMkC,SAAqB,OAAS,WACzG,uBAAOS,KAAK,SAASM,QAASP,KAAK9C,cAAegB,MAAM,iBAAiB4B,GAAG,cAG9E,4BAAIE,KAAK1C,MAAMG,mB,GA9KT+C,aCVHC,EAZS,SAACC,GACnBA,GAAeA,aAAuBC,UACxC,6BAAqB7B,MAAK,YAAkD,IAA/C8B,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCHdO,IAASC,OAEP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFjF,SAASmB,eAAe,SAM1BoD,M","file":"static/js/main.59bd6608.chunk.js","sourcesContent":["\nimport { Component } from 'react';\nimport {Tensor, InferenceSession} from 'onnxjs';\nimport * as onnxx from 'onnxjs';\nimport ndarray from \"ndarray\";\nimport ops from 'ndarray-ops';\nimport './App.css';\n\n\ninterface State {\n  loading: string, // Loading/status message displayed to user\n  modelLoaded: boolean, // flag to decide whether client model needs to be loaded -- needs to be loaded only during the first inference\n  class: string,  // output of resnet model, identified ImageNet class of the image\n  imageURL: string,\n  splitLayer: number // layer that determines split between client and server omdel\n}\n\ninterface Props {}\n\n// the client model will be downloaded and used by ONNX\nconst RESNET18_CLIENT_MODEL_URL = 'https://splitlearning.mit.edu/SplitLearningInference/client_models/';\n// the server model will be sent activations through a POST request\nconst RESNET18_SERVER_MODEL_URL = 'https://sl-demo-backend.herokuapp.com/inference';\n\nclass App extends Component<Props, State> {\n\n  session = new InferenceSession({ backendHint: 'cpu' });\n\n  constructor(props: Props) {\n    super(props);\n    this.state = {\n        loading: null,\n        modelLoaded: false,\n        class: null,\n        imageURL: null,\n        splitLayer: 5\n    };\n  }\n\n  /**\n   * Preprocessing (resize, crop, rearrange, normalize, totensor) image from canvas for ResNet inference\n   * @param img: HTMLImageElement\n   * @returns \n   */\n  preprocessImage = (img: HTMLImageElement) => {\n    // scale image so that the smaller dimension is 224 px\n    var orgWidth = img.width;\n    var orgHeight = img.height;\n    var resizedHeight = 224;\n    var resizedWidth = 224;\n    if (orgWidth > orgHeight) {\n      resizedWidth = (orgWidth / orgHeight) * 224;\n    } else if (orgWidth < orgHeight) {\n      resizedHeight = (orgHeight / orgWidth) * 224;\n    }\n    console.log(\"Resized (\" + orgWidth + \"px, \" + orgHeight + \"px) Image to (\" + resizedWidth + \"px, \" + resizedHeight + \"px)\")\n\n    // draw image on an HTML canvas\n    var canvas = document.createElement('canvas');\n    canvas.width = resizedWidth;\n    canvas.height = resizedHeight;\n    canvas.getContext('2d').drawImage(img, 0, 0, resizedWidth, resizedHeight);\n\n    // Get pixel data from a 224 x 224 crop of image \n    if (resizedHeight > resizedWidth) {\n      // vertically centered crop works best for vertical images\n      var data = canvas.getContext('2d').getImageData(0, (resizedHeight - 224)/2, 224, 224 + (resizedHeight - 224)/2).data;\n    } else {\n      // left crop works best for horizontal images\n      var data = canvas.getContext('2d').getImageData(0, 0, 224, 224).data;\n    }\n\n    // Rearrange values to a 3 channel 224 by 224 matrix (ignoring a value given by context.getImageData) \n    const dataFromImage = ndarray(new Float32Array(data), [224, 224, 4]);\n    const dataProcessed = ndarray(new Float32Array(224 * 224 * 3), [1, 3, 224, 224]);\n    ops.assign(dataProcessed.pick(0, 0, null, null), dataFromImage.pick(null, null, 2));\n    ops.assign(dataProcessed.pick(0, 1, null, null), dataFromImage.pick(null, null, 1));\n    ops.assign(dataProcessed.pick(0, 2, null, null), dataFromImage.pick(null, null, 0));\n\n    // Convert values from 0-255 to 0-1\n    ops.divseq(dataProcessed, 255);\n\n    // Normalize values so the mean and std for (r, g, b) is (0.485, 0.456, 0.406) and (0.229, 0.224, 0.225) respectively\n    ops.subseq(dataProcessed.pick(0, 0, null, null), 0.485);\n    ops.subseq(dataProcessed.pick(0, 1, null, null), 0.456);\n    ops.subseq(dataProcessed.pick(0, 2, null, null), 0.406);\n    ops.divseq(dataProcessed.pick(0, 0, null, null), 0.229);\n    ops.divseq(dataProcessed.pick(0, 1, null, null), 0.224);\n    ops.divseq(dataProcessed.pick(0, 2, null, null), 0.225);\n\n    // Convert finalized data to ONNX Tensor\n    var imgTensor = new Tensor((dataProcessed.data as Float32Array), 'float32', [1, 3, 224, 224])\n\n    return imgTensor;\n  }\n\n  classifyImage = async () => {\n    var inputImg = document.getElementById('imageView') as HTMLImageElement;\n\n    // Load the ResNet18 Client ONNX model on first inference only\n    if (!this.state.modelLoaded) {\n      this.setState({\n        loading: \"Loading client model...\"\n      });\n      await this.session.loadModel(RESNET18_CLIENT_MODEL_URL + \"resnet18_client_sl_\" + this.state.splitLayer + \".onnx\");\n      console.log(\"loaded client model from \" + RESNET18_CLIENT_MODEL_URL + \"resnet18_client_sl_\" + this.state.splitLayer + \".onnx\")\n      this.setState({\n        modelLoaded: true\n      });\n    }\n\n    if (inputImg) {\n      // Preprocess Image and perform client model inference\n      this.setState({\n        loading: \"Client model inference...\"\n      });\n      var imgTensor = this.preprocessImage(inputImg);\n      console.log(\"Input Image Tensor: \" + imgTensor.data)\n      const clientOutputMap = await this.session.run([imgTensor])\n      const splitActivation = clientOutputMap.values().next().value;\n      console.log(\"Output of Client Model (splitActivation): \" + splitActivation.data)\n      console.log(\"Dimensions: \" + splitActivation.dims)\n      console.log(splitActivation.data[0])\n      let npActivation = ndarray(splitActivation.data, splitActivation.dims)\n      console.log(npActivation)\n      console.log(npActivation.pick(0, 0, null, null))\n\n      // Perform server model inference on the split activation\n      this.setState({\n        loading: \"Sending split activations for server model inference (Split Layer=\" + this.state.splitLayer +\") ...\"\n      });\n      const requestOptions = {\n          method: 'POST',\n          headers: { 'Content-Type': 'application/json' },\n          body: JSON.stringify({dims: splitActivation.dims, data: Array.from(splitActivation.data), splitLayer: this.state.splitLayer})\n      };\n      console.log(\"Sending to \" + RESNET18_SERVER_MODEL_URL + \" with split layer of \" + this.state.splitLayer)\n      fetch(RESNET18_SERVER_MODEL_URL, requestOptions)\n          .then(response => response.json())\n          .then(data => {\n            // Display predicted class through app state\n            this.setState({class: data.class, loading: null});\n          });\n    } else {\n      console.error(\"There was an error accessing the uploaded image. Please try again.\")\n    }\n  }\n\n  /**\n   * Displays an image preview to the user whenever they upload an image\n   */\n  updatePreview = () => {\n    document.getElementById(\"imageLoader\").style.display = \"block\";\n    const file = (document.getElementById(\"inputImage\") as HTMLInputElement).files[0];\n    console.log(file)\n    if (file) {\n        this.setState({ imageURL: URL.createObjectURL(file) });\n    }\n    document.getElementById(\"imageLoader\").style.display = \"none\";\n  }\n\n  updateRangePreview = () => {\n    const splitLayer = (document.getElementById(\"splitLayerRange\") as HTMLInputElement).value;\n    this.setState({ splitLayer: parseInt(splitLayer) })\n  }\n\n  render() {\n    return (\n      <div className=\"App\">\n        <header className=\"App-header\">\n          <h1>ResNet18 Split Inference Demo</h1>\n          <p className=\"desc\">\n            A pre-trained ResNet18 model is split into <b>two</b> separate models — <b>client</b> (Alice) and <b>server</b> (Bob).\n          </p>\n          <img id=\"splitInferenceDiagram\" src=\"split_inference_diagram.png\"/>\n          <p className=\"desc\">\n            Your <b>uploaded image</b> is sent through the client model which returns the <b>split activations</b> of a cut layer within the full model. \n            <br />\n            <br />\n            These activations are sent to a server where the remaining of the inference is completed. The <b>output tensor</b> is then sent back to the client. \n            <br />\n            <br />\n            This allows you to perform <b>inference</b> on a model present on a <b>third party</b> server while <b>preserving your image's privacy</b>.\n          </p>\n          { (this.state.loading === null) ? (\n            <div>\n              <span>Split Layer: </span><input id=\"splitLayerRange\" type=\"range\" min=\"2\" value={this.state.splitLayer} max=\"9\" step=\"1\" onChange={this.updateRangePreview} />&nbsp;<span id=\"splitLayerPreview\">{this.state.splitLayer}</span>\n              <br />\n              <br />\n              <input onChange={this.updatePreview} type=\"file\" id=\"inputImage\" accept=\"image/jpeg\" />\n              <br />\n              <br />\n              <div id=\"imageLoader\" className=\"loader\"></div>\n              { this.state.class ? <p>Class: {this.state.class}</p> : <span><br /><br /></span> }\n              <img id=\"imageView\" src={this.state.imageURL} style={{display: (this.state.imageURL === null) ? \"none\" : \"block\"}}/>\n              <input type=\"submit\" onClick={this.classifyImage} value=\"Classify Image\" id=\"submit\" />\n            </div>\n          ) : (\n            <p>{this.state.loading}</p>\n          ) }\n        </header>\n      </div>\n    )\n  }\n\n}\n\nexport default App;\n","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  \n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}