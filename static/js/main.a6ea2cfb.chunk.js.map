{"version":3,"sources":["App.tsx","reportWebVitals.ts","index.tsx"],"names":["RESNET18_CLIENT_MODEL_URL","App","props","session","InferenceSession","backendHint","preprocessImage","img","orgWidth","width","orgHeight","height","resizedHeight","resizedWidth","console","log","canvas","document","createElement","getContext","drawImage","data","getImageData","dataFromImage","ndarray","Float32Array","dataProcessed","ops","assign","pick","divseq","subseq","Tensor","classifyImage","a","inputImg","getElementById","state","modelLoaded","setState","loading","loadModel","imgTensor","run","clientOutputMap","splitActivation","values","next","value","requestOptions","method","headers","body","JSON","stringify","dims","Array","from","fetch","then","response","json","class","error","updatePreview","style","display","file","files","imageURL","URL","createObjectURL","className","id","src","this","onChange","type","accept","onClick","Component","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode"],"mappings":"oUAkBMA,EAA4B,4EA4KnBC,E,kDApKb,WAAYC,GAAe,IAAD,8BACxB,cAAMA,IAHRC,QAAU,IAAIC,mBAAiB,CAAEC,YAAa,QAEpB,EAe1BC,gBAAkB,SAACC,GAEjB,IAAIC,EAAWD,EAAIE,MACfC,EAAYH,EAAII,OAChBC,EAAgB,IAChBC,EAAe,IACfL,EAAWE,EACbG,EAAgBL,EAAWE,EAAa,IAC/BF,EAAWE,IACpBE,EAAiBF,EAAYF,EAAY,KAE3CM,QAAQC,IAAI,YAAcP,EAAW,OAASE,EAAY,iBAAmBG,EAAe,OAASD,EAAgB,OAGrH,IAAII,EAASC,SAASC,cAAc,UAMpC,GALAF,EAAOP,MAAQI,EACfG,EAAOL,OAASC,EAChBI,EAAOG,WAAW,MAAMC,UAAUb,EAAK,EAAG,EAAGM,EAAcD,GAGvDA,EAAgBC,EAElB,IAAIQ,EAAOL,EAAOG,WAAW,MAAMG,aAAa,GAAIV,EAAgB,KAAK,EAAG,IAAK,KAAOA,EAAgB,KAAK,GAAGS,UAG5GA,EAAOL,EAAOG,WAAW,MAAMG,aAAa,EAAG,EAAG,IAAK,KAAKD,KAIlE,IAAME,EAAgBC,IAAQ,IAAIC,aAAaJ,GAAO,CAAC,IAAK,IAAK,IAC3DK,EAAgBF,IAAQ,IAAIC,aAAa,QAAgB,CAAC,EAAG,EAAG,IAAK,MAmB3E,OAlBAE,IAAIC,OAAOF,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAON,EAAcM,KAAK,KAAM,KAAM,IAChFF,IAAIC,OAAOF,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAON,EAAcM,KAAK,KAAM,KAAM,IAChFF,IAAIC,OAAOF,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAON,EAAcM,KAAK,KAAM,KAAM,IAGhFF,IAAIG,OAAOJ,EAAe,KAG1BC,IAAII,OAAOL,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MACjDF,IAAII,OAAOL,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MACjDF,IAAII,OAAOL,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MACjDF,IAAIG,OAAOJ,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MACjDF,IAAIG,OAAOJ,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MACjDF,IAAIG,OAAOJ,EAAcG,KAAK,EAAG,EAAG,KAAM,MAAO,MAGjC,IAAIG,SAAQN,EAAcL,KAAuB,UAAW,CAAC,EAAG,EAAG,IAAK,OA9DhE,EAmE1BY,cAnE0B,sBAmEV,oCAAAC,EAAA,yDACVC,EAAWlB,SAASmB,eAAe,aAGlC,EAAKC,MAAMC,YAJF,uBAKZ,EAAKC,SAAS,CACZC,QAAS,4BANC,SAQN,EAAKrC,QAAQsC,UAAUzC,GARjB,OASZc,QAAQC,IAAI,4BAA8Bf,GAC1C,EAAKuC,SAAS,CACZD,aAAa,IAXH,WAeVH,EAfU,wBAiBZ,EAAKI,SAAS,CACZC,QAAS,8BAEPE,EAAY,EAAKpC,gBAAgB6B,GACrCrB,QAAQC,IAAI,uBAAyB2B,EAAUrB,MArBnC,UAsBkB,EAAKlB,QAAQwC,IAAI,CAACD,IAtBpC,QAsBNE,EAtBM,OAuBNC,EAAkBD,EAAgBE,SAASC,OAAOC,MACxDlC,QAAQC,IAAI,6CAA+C8B,EAAgBxB,MAG3E,EAAKkB,SAAS,CACZC,QAAS,4DAELS,EAAiB,CACnBC,OAAQ,OACRC,QAAS,CAAE,eAAgB,oBAC3BC,KAAMC,KAAKC,UAAU,CAACC,KAAMV,EAAgBU,KAAMlC,KAAMmC,MAAMC,KAAKZ,EAAgBxB,SAEvFqC,MA5G4B,kDA4GKT,GAC5BU,MAAK,SAAAC,GAAQ,OAAIA,EAASC,UAC1BF,MAAK,SAAAtC,GAEJ,EAAKkB,SAAS,CAACuB,MAAOzC,EAAKyC,MAAOtB,QAAS,UAvCrC,wBA0CZ1B,QAAQiD,MAAM,sEA1CF,4CAnEU,EAoH1BC,cAAgB,WACd/C,SAASmB,eAAe,eAAe6B,MAAMC,QAAU,QACvD,IAAMC,EAAQlD,SAASmB,eAAe,cAAmCgC,MAAM,GAC/EtD,QAAQC,IAAIoD,GACRA,GACA,EAAK5B,SAAS,CAAE8B,SAAUC,IAAIC,gBAAgBJ,KAElDlD,SAASmB,eAAe,eAAe6B,MAAMC,QAAU,QAzHvD,EAAK7B,MAAQ,CACTG,QAAS,KACTF,aAAa,EACbwB,MAAO,KACPO,SAAU,MANU,E,0CA8H1B,WACE,OACE,qBAAKG,UAAU,MAAf,SACE,yBAAQA,UAAU,aAAlB,UACE,+DACA,oBAAGA,UAAU,OAAb,wDAC6C,oCAD7C,2BAC0E,uCAD1E,gBACoG,uCADpG,aAGA,qBAAKC,GAAG,wBAAwBC,IAAI,gCACpC,oBAAGF,UAAU,OAAb,kBACO,+CADP,uDACgF,kDADhF,yCAEE,uBACA,uBAHF,iGAIgG,8CAJhG,oCAKE,uBACA,uBANF,8BAO6B,0CAP7B,4BAOsE,4CAPtE,iBAOsG,gEAPtG,OAS0B,OAAvBG,KAAKtC,MAAMG,QACZ,gCACE,uBAAOoC,SAAUD,KAAKX,cAAea,KAAK,OAAOJ,GAAG,aAAaK,OAAO,eACxE,uBACA,uBACA,qBAAKL,GAAG,cAAcD,UAAU,WAC9BG,KAAKtC,MAAMyB,MAAQ,wCAAWa,KAAKtC,MAAMyB,SAAa,iCAAM,uBAAM,0BACpE,qBAAKW,GAAG,YAAYC,IAAKC,KAAKtC,MAAMgC,SAAUJ,MAAO,CAACC,QAAkC,OAAxBS,KAAKtC,MAAMgC,SAAqB,OAAS,WACzG,uBAAOQ,KAAK,SAASE,QAASJ,KAAK1C,cAAee,MAAM,iBAAiByB,GAAG,cAG9E,4BAAIE,KAAKtC,MAAMG,mB,GA/JTwC,aCRHC,EAZS,SAACC,GACnBA,GAAeA,aAAuBC,UACxC,6BAAqBxB,MAAK,YAAkD,IAA/CyB,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCHdO,IAASC,OAEP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEF1E,SAASmB,eAAe,SAM1B6C,M","file":"static/js/main.a6ea2cfb.chunk.js","sourcesContent":["\nimport { Component } from 'react';\nimport {Tensor, InferenceSession} from 'onnxjs';\nimport ndarray from \"ndarray\";\nimport ops from 'ndarray-ops';\nimport './App.css';\n\n\ninterface State {\n  loading: string, // Loading/status message displayed to user\n  modelLoaded: boolean, // flag to decide whether client model needs to be loaded -- needs to be loaded only during the first inference\n  class: string,  // output of resnet model, identified ImageNet class of the image\n  imageURL: string\n}\n\ninterface Props {}\n\n// the client model will be downloaded and used by ONNX\nconst RESNET18_CLIENT_MODEL_URL = 'https://splitlearning.mit.edu/SplitLearningInference/resnet18_client.onnx';\n// the server model will be sent activations through a POST request\nconst RESNET18_SERVER_MODEL_URL = 'https://sl-demo-backend.herokuapp.com/inference';\n\nclass App extends Component<Props, State> {\n\n  session = new InferenceSession({ backendHint: 'cpu' });\n\n  constructor(props: Props) {\n    super(props);\n    this.state = {\n        loading: null,\n        modelLoaded: false,\n        class: null,\n        imageURL: null\n    };\n  }\n\n  /**\n   * Preprocessing (resize, crop, rearrange, normalize, totensor) image from canvas for ResNet inference\n   * @param img: HTMLImageElement\n   * @returns \n   */\n  preprocessImage = (img: HTMLImageElement) => {\n    // scale image so that the smaller dimension is 224 px\n    var orgWidth = img.width;\n    var orgHeight = img.height;\n    var resizedHeight = 224;\n    var resizedWidth = 224;\n    if (orgWidth > orgHeight) {\n      resizedWidth = (orgWidth / orgHeight) * 224;\n    } else if (orgWidth < orgHeight) {\n      resizedHeight = (orgHeight / orgWidth) * 224;\n    }\n    console.log(\"Resized (\" + orgWidth + \"px, \" + orgHeight + \"px) Image to (\" + resizedWidth + \"px, \" + resizedHeight + \"px)\")\n\n    // draw image on an HTML canvas\n    var canvas = document.createElement('canvas');\n    canvas.width = resizedWidth;\n    canvas.height = resizedHeight;\n    canvas.getContext('2d').drawImage(img, 0, 0, resizedWidth, resizedHeight);\n\n    // Get pixel data from a 224 x 224 crop of image \n    if (resizedHeight > resizedWidth) {\n      // vertically centered crop works best for vertical images\n      var data = canvas.getContext('2d').getImageData(0, (resizedHeight - 224)/2, 224, 224 + (resizedHeight - 224)/2).data;\n    } else {\n      // left crop works best for horizontal images\n      var data = canvas.getContext('2d').getImageData(0, 0, 224, 224).data;\n    }\n\n    // Rearrange values to a 3 channel 224 by 224 matrix (ignoring a value given by context.getImageData) \n    const dataFromImage = ndarray(new Float32Array(data), [224, 224, 4]);\n    const dataProcessed = ndarray(new Float32Array(224 * 224 * 3), [1, 3, 224, 224]);\n    ops.assign(dataProcessed.pick(0, 0, null, null), dataFromImage.pick(null, null, 2));\n    ops.assign(dataProcessed.pick(0, 1, null, null), dataFromImage.pick(null, null, 1));\n    ops.assign(dataProcessed.pick(0, 2, null, null), dataFromImage.pick(null, null, 0));\n\n    // Convert values from 0-255 to 0-1\n    ops.divseq(dataProcessed, 255);\n\n    // Normalize values so the mean and std for (r, g, b) is (0.485, 0.456, 0.406) and (0.229, 0.224, 0.225) respectively\n    ops.subseq(dataProcessed.pick(0, 0, null, null), 0.485);\n    ops.subseq(dataProcessed.pick(0, 1, null, null), 0.456);\n    ops.subseq(dataProcessed.pick(0, 2, null, null), 0.406);\n    ops.divseq(dataProcessed.pick(0, 0, null, null), 0.229);\n    ops.divseq(dataProcessed.pick(0, 1, null, null), 0.224);\n    ops.divseq(dataProcessed.pick(0, 2, null, null), 0.225);\n\n    // Convert finalized data to ONNX Tensor\n    var imgTensor = new Tensor((dataProcessed.data as Float32Array), 'float32', [1, 3, 224, 224])\n\n    return imgTensor;\n  }\n\n  classifyImage = async () => {\n    var inputImg = document.getElementById('imageView') as HTMLImageElement;\n\n    // Load the ResNet18 Client ONNX model on first inference only\n    if (!this.state.modelLoaded) {\n      this.setState({\n        loading: \"Loading client model...\"\n      });\n      await this.session.loadModel(RESNET18_CLIENT_MODEL_URL);\n      console.log(\"loaded client model from \" + RESNET18_CLIENT_MODEL_URL)\n      this.setState({\n        modelLoaded: true\n      });\n    }\n\n    if (inputImg) {\n      // Preprocess Image and perform client model inference\n      this.setState({\n        loading: \"Client model inference...\"\n      });\n      var imgTensor = this.preprocessImage(inputImg);\n      console.log(\"Input Image Tensor: \" + imgTensor.data)\n      const clientOutputMap = await this.session.run([imgTensor])\n      const splitActivation = clientOutputMap.values().next().value;\n      console.log(\"Output of Client Model (splitActivation): \" + splitActivation.data)\n\n      // Perform server model inference on the split activation\n      this.setState({\n        loading: \"Sending split activations for server model inference...\"\n      });\n      const requestOptions = {\n          method: 'POST',\n          headers: { 'Content-Type': 'application/json' },\n          body: JSON.stringify({dims: splitActivation.dims, data: Array.from(splitActivation.data)})\n      };\n      fetch(RESNET18_SERVER_MODEL_URL, requestOptions)\n          .then(response => response.json())\n          .then(data => {\n            // Display predicted class through app state\n            this.setState({class: data.class, loading: null});\n          });\n    } else {\n      console.error(\"There was an error accessing the uploaded image. Please try again.\")\n    }\n  }\n\n  /**\n   * Displays an image preview to the user whenever they upload an image\n   */\n  updatePreview = () => {\n    document.getElementById(\"imageLoader\").style.display = \"block\";\n    const file = (document.getElementById(\"inputImage\") as HTMLInputElement).files[0];\n    console.log(file)\n    if (file) {\n        this.setState({ imageURL: URL.createObjectURL(file) });\n    }\n    document.getElementById(\"imageLoader\").style.display = \"none\";\n  }\n\n  render() {\n    return (\n      <div className=\"App\">\n        <header className=\"App-header\">\n          <h1>ResNet18 Split Inference Demo</h1>\n          <p className=\"desc\">\n            A pre-trained ResNet18 model is split into <b>two</b> separate models — <b>client</b> (Alice) and <b>server</b> (Bob).\n          </p>\n          <img id=\"splitInferenceDiagram\" src=\"split_inference_diagram.png\"/>\n          <p className=\"desc\">\n            Your <b>uploaded image</b> is sent through the client model which returns the <b>split activations</b> of a cut layer within the full model. \n            <br />\n            <br />\n            These activations are sent to a server where the remaining of the inference is completed. The <b>output tensor</b> is then sent back to the client. \n            <br />\n            <br />\n            This allows you to perform <b>inference</b> on a model present on a <b>third party</b> server while <b>preserving your image's privacy</b>.\n          </p>\n          { (this.state.loading === null) ? (\n            <div>\n              <input onChange={this.updatePreview} type=\"file\" id=\"inputImage\" accept=\"image/jpeg\" />\n              <br />\n              <br />\n              <div id=\"imageLoader\" className=\"loader\"></div>\n              { this.state.class ? <p>Class: {this.state.class}</p> : <span><br /><br /></span> }\n              <img id=\"imageView\" src={this.state.imageURL} style={{display: (this.state.imageURL === null) ? \"none\" : \"block\"}}/>\n              <input type=\"submit\" onClick={this.classifyImage} value=\"Classify Image\" id=\"submit\" />\n            </div>\n          ) : (\n            <p>{this.state.loading}</p>\n          ) }\n        </header>\n      </div>\n    )\n  }\n\n}\n\nexport default App;\n","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  \n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}